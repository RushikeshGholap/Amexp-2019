{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem Statement Predicting Coupon Redemption XYZ Credit Card company regularly helps it’s merchants understand their data better and take key business decisions accurately by providing machine learning and analytics consulting. ABC is an established Brick & Mortar retailer that frequently conducts marketing campaigns for its diverse product range. As a merchant of XYZ, they have sought XYZ to assist them in their discount marketing process using the power of machine learning. Can you wear the AmExpert hat and help out ABC?\n",
    "\n",
    "Discount marketing and coupon usage are very widely used promotional techniques to attract new customers and to retain & reinforce loyalty of existing customers. The measurement of a consumer’s propensity towards coupon usage and the prediction of the redemption behaviour are crucial parameters in assessing the effectiveness of a marketing campaign.\n",
    "\n",
    "ABC’s promotions are shared across various channels including email, notifications, etc. A number of these campaigns include coupon discounts that are offered for a specific product/range of products. The retailer would like the ability to predict whether customers redeem the coupons received across channels, which will enable the retailer’s marketing team to accurately design coupon construct, and develop more precise and targeted marketing strategies.\n",
    "\n",
    "The data available in this problem contains the following information, including the details of a sample of campaigns and coupons used in previous campaigns -\n",
    "\n",
    "User Demographic Details Campaign and coupon Details Product details Previous transactions Based on previous transaction & performance data from the last 18 campaigns, predict the probability for the next 10 campaigns in the test set for each coupon and customer combination, whether the customer will redeem the coupon or not?\n",
    "\n",
    "Dataset Description Here is the schema for the different data tables available. The detailed data dictionary is provided next.\n",
    "\n",
    "You are provided with the following files in train.zip:\n",
    "\n",
    "train.csv: Train data containing the coupons offered to the given customers under the 18 campaigns\n",
    "\n",
    "Variable Definition id Unique id for coupon customer impression campaign_id Unique id for a discount campaign coupon_id Unique id for a discount coupon customer_id Unique id for a customer redemption_status (target) (0 - Coupon not redeemed, 1 - Coupon redeemed) campaign_data.csv: Campaign information for each of the 28 campaigns\n",
    "\n",
    "Variable Definition campaign_id Unique id for a discount campaign campaign_type Anonymised Campaign Type (X/Y) start_date Campaign Start Date end_date Campaign End Date coupon_item_mapping.csv: Mapping of coupon and items valid for discount under that coupon\n",
    "\n",
    "Variable Definition coupon_id Unique id for a discount coupon (no order) item_id Unique id for items for which given coupon is valid (no order) customer_demographics.csv: Customer demographic information for some customers\n",
    "\n",
    "Variable Definition customer_id Unique id for a customer age_range Age range of customer family in years marital_status Married/Single rented 0 - not rented accommodation, 1 - rented accommodation family_size Number of family members no_of_children Number of children in the family income_bracket Label Encoded Income Bracket (Higher income corresponds to higher number) customer_transaction_data.csv: Transaction data for all customers for duration of campaigns in the train data\n",
    "\n",
    "Variable Definition date Date of Transaction customer_id Unique id for a customer item_id Unique id for item quantity quantity of item bought selling_price Sales value of the transaction other_discount Discount from other sources such as manufacturer coupon/loyalty card coupon_discount Discount availed from retailer coupon item_data.csv: Item information for each item sold by the retailer\n",
    "\n",
    "Variable Definition item_id Unique id for item brand Unique id for item brand brand_type Brand Type (local/Established) category Item Category test.csv: Contains the coupon customer combination for which redemption status is to be predicted\n",
    "\n",
    "Variable Definition id Unique id for coupon customer impression campaign_id Unique id for a discount campaign coupon_id Unique id for a discount coupon customer_id Unique id for a customer *Campaign, coupon and customer data for test set is also contained in train.zip\n",
    "\n",
    "sample_submission.csv: This file contains the format in which you have to submit your predictions.\n",
    "\n",
    "To summarise the entire process:\n",
    "\n",
    "Customers receive coupons under various campaigns and may choose to redeem it. They can redeem the given coupon for any valid product for that coupon as per coupon item mapping within the duration between campaign start date and end date Next, the customer will redeem the coupon for an item at the retailer store and that will reflect in the transaction table in the column coupon_discount.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "https://www.kaggle.com/bharath901/amexpert-2019/data#\n",
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_selection import RFE\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Function to various files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Defining a Class to import the Data into a pandas DataFrame for analysis\n",
    "- Method to storing the Data into a DataFrame\n",
    "- Method to extracting Information of the Data to understand datatype associated with each column\n",
    "- Method to describing the Data\n",
    "- Method to understanding Null values distribution\n",
    "- Method to understanding Unique values distribution\n",
    "'''\n",
    "\n",
    "class import_data():\n",
    "    \n",
    "    '''\n",
    "    Method to extract and store the data as pandas dataframe\n",
    "    '''\n",
    "    def __init__(self,path):\n",
    "        self.raw_data = pd.read_csv(path)\n",
    "        display (self.raw_data.head(10))\n",
    "        \n",
    "\n",
    "    '''\n",
    "    Method to extract information about the data and display\n",
    "    '''\n",
    "    def get_info(self):\n",
    "        display (self.raw_data.info())\n",
    "        \n",
    "    '''\n",
    "    Method to describe the data\n",
    "    '''\n",
    "    def get_describe(self):\n",
    "        display (self.raw_data.describe())\n",
    "        \n",
    "    '''\n",
    "    Mehtod to understand Null values distribution\n",
    "    '''\n",
    "    def null_value(self):\n",
    "        col_null = pd.DataFrame(self.raw_data.isnull().sum()).reset_index()\n",
    "        col_null.columns = ['DataColumns','NullCount']\n",
    "        col_null['NullCount_Pct'] = round((col_null['NullCount']/self.raw_data.shape[0])*100,2)\n",
    "        display (col_null)\n",
    "        \n",
    "    '''\n",
    "    Method to understand Unique values distribution\n",
    "    '''\n",
    "    def unique_value(self):\n",
    "        col_uniq = pd.DataFrame(self.raw_data.nunique()).reset_index()\n",
    "        col_uniq.columns = ['DataColumns','UniqCount']\n",
    "        col_uniq_cnt = pd.DataFrame(self.raw_data.count(axis=0)).reset_index()\n",
    "        col_uniq_cnt.columns = ['DataColumns','UniqCount']\n",
    "        col_uniq['UniqCount_Pct'] = round((col_uniq['UniqCount']/col_uniq_cnt['UniqCount'])*100,2)\n",
    "        display (col_uniq)\n",
    "    '''\n",
    "    Method to return the dataset as dataframe\n",
    "    '''\n",
    "    def return_data(self):\n",
    "        base_loan_data = self.raw_data\n",
    "        return (base_loan_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>coupon_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>redemption_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>27</td>\n",
       "      <td>1053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>116</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>635</td>\n",
       "      <td>205</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>644</td>\n",
       "      <td>1050</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1017</td>\n",
       "      <td>1489</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>795</td>\n",
       "      <td>793</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>444</td>\n",
       "      <td>590</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>29</td>\n",
       "      <td>538</td>\n",
       "      <td>368</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>30</td>\n",
       "      <td>857</td>\n",
       "      <td>523</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>559</td>\n",
       "      <td>679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  campaign_id  coupon_id  customer_id  redemption_status\n",
       "0   1           13         27         1053                  0\n",
       "1   2           13        116           48                  0\n",
       "2   6            9        635          205                  0\n",
       "3   7           13        644         1050                  0\n",
       "4   9            8       1017         1489                  0\n",
       "5  11           11        795          793                  0\n",
       "6  14            9        444          590                  0\n",
       "7  15           29        538          368                  0\n",
       "8  17           30        857          523                  0\n",
       "9  19            2        559          679                  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "Evaluation and Analysis starts here for train.csv\n",
    "'''\n",
    "#path = str(input('Enter the path to load the dataset:'))\n",
    "path = './train.csv'\n",
    "print ('='*100)\n",
    "data = import_data(path)\n",
    "#data.get_info()\n",
    "#data.null_value()\n",
    "#data.unique_value()\n",
    "#data.get_describe()\n",
    "train_data = data.return_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>campaign_type</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>Y</td>\n",
       "      <td>21/10/13</td>\n",
       "      <td>20/12/13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>Y</td>\n",
       "      <td>21/10/13</td>\n",
       "      <td>22/11/13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>Y</td>\n",
       "      <td>07/09/13</td>\n",
       "      <td>16/11/13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>Y</td>\n",
       "      <td>08/10/13</td>\n",
       "      <td>15/11/13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>Y</td>\n",
       "      <td>16/09/13</td>\n",
       "      <td>18/10/13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>X</td>\n",
       "      <td>16/09/13</td>\n",
       "      <td>18/10/13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>X</td>\n",
       "      <td>10/08/13</td>\n",
       "      <td>04/10/13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>Y</td>\n",
       "      <td>26/08/13</td>\n",
       "      <td>27/09/13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>Y</td>\n",
       "      <td>29/07/13</td>\n",
       "      <td>30/08/13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>Y</td>\n",
       "      <td>15/07/13</td>\n",
       "      <td>16/08/13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   campaign_id campaign_type start_date  end_date\n",
       "0           24             Y   21/10/13  20/12/13\n",
       "1           25             Y   21/10/13  22/11/13\n",
       "2           20             Y   07/09/13  16/11/13\n",
       "3           23             Y   08/10/13  15/11/13\n",
       "4           21             Y   16/09/13  18/10/13\n",
       "5           22             X   16/09/13  18/10/13\n",
       "6           18             X   10/08/13  04/10/13\n",
       "7           19             Y   26/08/13  27/09/13\n",
       "8           17             Y   29/07/13  30/08/13\n",
       "9           16             Y   15/07/13  16/08/13"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "Evaluation and Analysis starts here for Campaign Data\n",
    "'''\n",
    "#path = str(input('Enter the path to load the dataset:'))\n",
    "path = './campaign_data.csv'\n",
    "print ('='*100)\n",
    "data = import_data(path)\n",
    "#data.get_info()\n",
    "#data.null_value()\n",
    "#data.unique_value()\n",
    "#data.get_describe()\n",
    "campaign_data = data.return_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coupon_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>494</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>522</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>518</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>520</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>529</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>524</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>522</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>518</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   coupon_id  item_id\n",
       "0        105       37\n",
       "1        107       75\n",
       "2        494       76\n",
       "3        522       77\n",
       "4        518       77\n",
       "5        520       77\n",
       "6        529       77\n",
       "7        524       77\n",
       "8        522       81\n",
       "9        518       81"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "Evaluation and Analysis starts here for Coupon Data\n",
    "'''\n",
    "#path = str(input('Enter the path to load the dataset:'))\n",
    "path = './coupon_item_mapping.csv'\n",
    "print ('='*100)\n",
    "data = import_data(path)\n",
    "#data.get_info()\n",
    "#data.null_value()\n",
    "#data.unique_value()\n",
    "#data.get_describe()\n",
    "coupon_data = data.return_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>brand</th>\n",
       "      <th>brand_type</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Established</td>\n",
       "      <td>Grocery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Established</td>\n",
       "      <td>Miscellaneous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "      <td>Local</td>\n",
       "      <td>Bakery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>56</td>\n",
       "      <td>Local</td>\n",
       "      <td>Grocery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>Local</td>\n",
       "      <td>Grocery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>56</td>\n",
       "      <td>Local</td>\n",
       "      <td>Grocery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>56</td>\n",
       "      <td>Local</td>\n",
       "      <td>Pharmaceutical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>56</td>\n",
       "      <td>Local</td>\n",
       "      <td>Bakery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>Local</td>\n",
       "      <td>Grocery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>56</td>\n",
       "      <td>Local</td>\n",
       "      <td>Grocery</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id  brand   brand_type        category\n",
       "0        1      1  Established         Grocery\n",
       "1        2      1  Established   Miscellaneous\n",
       "2        3     56        Local          Bakery\n",
       "3        4     56        Local         Grocery\n",
       "4        5     56        Local         Grocery\n",
       "5        6     56        Local         Grocery\n",
       "6        7     56        Local  Pharmaceutical\n",
       "7        8     56        Local          Bakery\n",
       "8        9     11        Local         Grocery\n",
       "9       10     56        Local         Grocery"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "Evaluation and Analysis starts here for Item Data\n",
    "'''\n",
    "#path = str(input('Enter the path to load the dataset:'))\n",
    "path = './item_data.csv'\n",
    "print ('='*100)\n",
    "data = import_data(path)\n",
    "#data.get_info()\n",
    "#data.null_value()\n",
    "#data.unique_value()\n",
    "#data.get_describe()\n",
    "item_data = data.return_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>age_range</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>rented</th>\n",
       "      <th>family_size</th>\n",
       "      <th>no_of_children</th>\n",
       "      <th>income_bracket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>70+</td>\n",
       "      <td>Married</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>46-55</td>\n",
       "      <td>Married</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>26-35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>26-35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>46-55</td>\n",
       "      <td>Single</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>70+</td>\n",
       "      <td>Single</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>46-55</td>\n",
       "      <td>Married</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>36-45</td>\n",
       "      <td>Single</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>26-35</td>\n",
       "      <td>Married</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>46-55</td>\n",
       "      <td>Married</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id age_range marital_status  rented family_size no_of_children  \\\n",
       "0            1       70+        Married       0           2            NaN   \n",
       "1            6     46-55        Married       0           2            NaN   \n",
       "2            7     26-35            NaN       0           3              1   \n",
       "3            8     26-35            NaN       0           4              2   \n",
       "4           10     46-55         Single       0           1            NaN   \n",
       "5           11       70+         Single       0           2            NaN   \n",
       "6           12     46-55        Married       0           2            NaN   \n",
       "7           13     36-45         Single       0           1            NaN   \n",
       "8           14     26-35        Married       1           2            NaN   \n",
       "9           15     46-55        Married       0           2            NaN   \n",
       "\n",
       "   income_bracket  \n",
       "0               4  \n",
       "1               5  \n",
       "2               3  \n",
       "3               6  \n",
       "4               5  \n",
       "5               1  \n",
       "6               7  \n",
       "7               2  \n",
       "8               6  \n",
       "9               6  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "Evaluation and Analysis starts here for Customer Demographic\n",
    "'''\n",
    "#path = str(input('Enter the path to load the dataset:'))\n",
    "path = './customer_demographics.csv'\n",
    "print ('='*100)\n",
    "data = import_data(path)\n",
    "#data.get_info()\n",
    "#data.null_value()\n",
    "#data.unique_value()\n",
    "#data.get_describe()\n",
    "cust_demo_data = data.return_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>quantity</th>\n",
       "      <th>selling_price</th>\n",
       "      <th>other_discount</th>\n",
       "      <th>coupon_discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2012-01-02</td>\n",
       "      <td>1501</td>\n",
       "      <td>26830</td>\n",
       "      <td>1</td>\n",
       "      <td>35.26</td>\n",
       "      <td>-10.69</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-02</td>\n",
       "      <td>1501</td>\n",
       "      <td>54253</td>\n",
       "      <td>1</td>\n",
       "      <td>53.43</td>\n",
       "      <td>-13.89</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2012-01-02</td>\n",
       "      <td>1501</td>\n",
       "      <td>31962</td>\n",
       "      <td>1</td>\n",
       "      <td>106.50</td>\n",
       "      <td>-14.25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2012-01-02</td>\n",
       "      <td>1501</td>\n",
       "      <td>33647</td>\n",
       "      <td>1</td>\n",
       "      <td>67.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2012-01-02</td>\n",
       "      <td>1501</td>\n",
       "      <td>48199</td>\n",
       "      <td>1</td>\n",
       "      <td>71.24</td>\n",
       "      <td>-28.14</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2012-01-02</td>\n",
       "      <td>1501</td>\n",
       "      <td>57397</td>\n",
       "      <td>1</td>\n",
       "      <td>71.24</td>\n",
       "      <td>-28.14</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2012-01-02</td>\n",
       "      <td>857</td>\n",
       "      <td>12424</td>\n",
       "      <td>1</td>\n",
       "      <td>106.50</td>\n",
       "      <td>-14.25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2012-01-02</td>\n",
       "      <td>857</td>\n",
       "      <td>14930</td>\n",
       "      <td>1</td>\n",
       "      <td>110.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2012-01-02</td>\n",
       "      <td>857</td>\n",
       "      <td>16657</td>\n",
       "      <td>1</td>\n",
       "      <td>89.05</td>\n",
       "      <td>-35.26</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2012-01-02</td>\n",
       "      <td>67</td>\n",
       "      <td>10537</td>\n",
       "      <td>3</td>\n",
       "      <td>32.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  customer_id  item_id  quantity  selling_price  other_discount  \\\n",
       "0  2012-01-02         1501    26830         1          35.26          -10.69   \n",
       "1  2012-01-02         1501    54253         1          53.43          -13.89   \n",
       "2  2012-01-02         1501    31962         1         106.50          -14.25   \n",
       "3  2012-01-02         1501    33647         1          67.32            0.00   \n",
       "4  2012-01-02         1501    48199         1          71.24          -28.14   \n",
       "5  2012-01-02         1501    57397         1          71.24          -28.14   \n",
       "6  2012-01-02          857    12424         1         106.50          -14.25   \n",
       "7  2012-01-02          857    14930         1         110.07            0.00   \n",
       "8  2012-01-02          857    16657         1          89.05          -35.26   \n",
       "9  2012-01-02           67    10537         3          32.06            0.00   \n",
       "\n",
       "   coupon_discount  \n",
       "0              0.0  \n",
       "1              0.0  \n",
       "2              0.0  \n",
       "3              0.0  \n",
       "4              0.0  \n",
       "5              0.0  \n",
       "6              0.0  \n",
       "7              0.0  \n",
       "8              0.0  \n",
       "9              0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "Evaluation and Analysis starts here for Customer Transaction\n",
    "'''\n",
    "#path = str(input('Enter the path to load the dataset:'))\n",
    "path = './customer_transaction_data.csv'\n",
    "print ('='*100)\n",
    "data = import_data(path)\n",
    "#data.get_info()\n",
    "#data.null_value()\n",
    "#data.unique_value()\n",
    "#data.get_describe()\n",
    "cust_tran_data = data.return_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function to write the experiment result to csv file\n",
    "'''\n",
    "\n",
    "file_write_cnt = 1\n",
    "\n",
    "# writing the baseline results to csv file \n",
    "\n",
    "def write_file(F1,F2,F3,F4,F5,F6,F7,F8,F9,F10,F11):\n",
    "        \n",
    "    # field names \n",
    "    fields = ['Expt No','Outlier Treatment','Skewness Treatment','Null Treatment',\n",
    "              'No of Features','Feature Selected','Model Used','Precision for 1',\n",
    "              'Recall for 1','Accuracy','Comment']\n",
    "  \n",
    "    # data in the file\n",
    "    rows = [[F1,F2,F3,F4,F5,F6,F7,F8,F9,F10,F11]]\n",
    "        \n",
    "    # name of csv file \n",
    "    filename = \"./score_dashboard.csv\"\n",
    "  \n",
    "    if int(F1) == 1:\n",
    "        # writing to csv file \n",
    "        with open(filename, 'w') as csvfile: \n",
    "        \n",
    "            # creating a csv writer object \n",
    "            csvwriter = csv.writer(csvfile) \n",
    "      \n",
    "            # writing the fields \n",
    "            csvwriter.writerow(fields) \n",
    "      \n",
    "            # writing the data rows \n",
    "            csvwriter.writerows(rows)\n",
    "    \n",
    "    if int(F1) > 1:\n",
    "        # writing to csv file \n",
    "        with open(filename, 'a') as csvfile: \n",
    "        \n",
    "            # creating a csv writer object \n",
    "            csvwriter = csv.writer(csvfile) \n",
    "      \n",
    "            # writing the data rows \n",
    "            csvwriter.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function to convert the date into quarter\n",
    "'''\n",
    "\n",
    "def date_q(date,split):\n",
    "    \n",
    "    if split == '/':\n",
    "        \n",
    "        \"\"\"\n",
    "        Convert Date to Quarter when separated with /\n",
    "        \"\"\"\n",
    "        qdate = date.strip().split('/')[1:]\n",
    "        qdate1 = qdate[0]\n",
    "\n",
    "        if qdate1 in ['01','02','03']:\n",
    "            return (str('Q1' + '-' + qdate[1]))\n",
    "        if qdate1 in ['04','05','06']:\n",
    "            return (str('Q2' + '-' + qdate[1]))\n",
    "        if qdate1 in ['07','08','09']:\n",
    "            return (str('Q3' + '-' + qdate[1]))\n",
    "        if qdate1 in ['10','11','12']:\n",
    "            return (str('Q4' + '-' + qdate[1]))\n",
    "        \n",
    "    if split == '-':\n",
    "        \n",
    "        \"\"\"\n",
    "        Convert Date to Quarter when separated with -\n",
    "        \"\"\"\n",
    "        qdate = date.strip().split('-')[0:2]\n",
    "        qdate1 = qdate[1]\n",
    "        qdate2 = str(qdate[0])\n",
    "        if qdate1 in ['01','02','03']:\n",
    "            return (str('Q1' + '-' + qdate2[2:]))\n",
    "        if qdate1 in ['04','05','06']:\n",
    "            return (str('Q2' + '-' + qdate2[2:]))\n",
    "        if qdate1 in ['07','08','09']:\n",
    "            return (str('Q3' + '-' + qdate2[2:]))\n",
    "        if qdate1 in ['10','11','12']:\n",
    "            return (str('Q4' + '-' + qdate2[2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function to aggregate Customer Transaction Data\n",
    "'''\n",
    "\n",
    "def tran_summation(column):\n",
    "    cust_tran_data_expt['tot_'+column] = pd.DataFrame(cust_tran_data_expt.groupby(['customer_id','item_id','coupon_id'])[column].transform('sum'))\n",
    "    cust_tran_data_expt.drop([column],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "def tran_summation_1(column):\n",
    "    cust_tran_data_expt['tot_'+column] = pd.DataFrame(cust_tran_data_expt.groupby(['customer_id','item_id','coupon_id','tran_date_q'])[column].transform('sum'))\n",
    "    cust_tran_data_expt.drop([column],axis=1,inplace=True)\n",
    "    \n",
    "def tran_summation_2(column):\n",
    "    cust_tran_data_expt['tot_'+column] = pd.DataFrame(cust_tran_data_expt.groupby(['customer_id','coupon_id'])[column].transform('sum'))\n",
    "    cust_tran_data_expt.drop([column],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function to label encode\n",
    "'''\n",
    "\n",
    "def label_encode(column):\n",
    "    train_data_merge[column] = train_data_merge[column].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function to convert Categorical column to Integer using Coupon Redemption percentage\n",
    "'''\n",
    "\n",
    "def cat_percent(column):\n",
    "    train_data_merge[column+'_redeem_sum'] = pd.DataFrame(train_data_merge.groupby([column])['redemption_status'].transform('sum'))\n",
    "    train_data_merge[column+'_redeem_count'] = pd.DataFrame(train_data_merge.groupby([column])['redemption_status'].transform('count'))\n",
    "    train_data_merge[column+'_redeem_percent'] = pd.DataFrame(train_data_merge[column+'_redeem_sum']*100/train_data_merge[column+'_redeem_count'])\n",
    "    train_data_merge.drop(column,axis=1,inplace=True)\n",
    "    train_data_merge.drop([column+'_redeem_sum'],axis=1,inplace=True)\n",
    "    train_data_merge.drop([column+'_redeem_count'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To define baseline model with basic data preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_demo_data_expt = cust_demo_data.copy()\n",
    "cust_demo_data_expt['marital_status'].fillna('Unspecified',inplace=True)\n",
    "cust_demo_data_expt['no_of_children'].fillna(0,inplace=True)\n",
    "cust_demo_data_expt['age_range'].replace(['18-25','26-35','36-45','46-55','56-70','70+'],[18,26,36,46,56,70],inplace=True)\n",
    "cust_demo_data_expt['family_size'].replace('5+',5,inplace=True)\n",
    "cust_demo_data_expt['no_of_children'].replace('3+',3,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_tran_data_expt = cust_tran_data.copy()\n",
    "cust_tran_data_expt = pd.merge(cust_tran_data_expt,coupon_data,how='inner',on='item_id')\n",
    "cust_tran_data_expt.drop('date',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['quantity','coupon_discount','other_discount','selling_price']:\n",
    "    tran_summation(column)\n",
    "\n",
    "cust_tran_data_expt.drop_duplicates(subset=['customer_id','item_id','coupon_id'], keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_merge = pd.merge(train_data,cust_tran_data_expt,how='inner',on=['customer_id','coupon_id'])\n",
    "train_data_merge = pd.merge(train_data_merge,cust_demo_data_expt,how='left',on='customer_id')\n",
    "train_data_merge = pd.merge(train_data_merge,item_data,how='left',on='item_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_merge.drop('marital_status',axis=1,inplace=True)\n",
    "train_data_merge.fillna({'age_range':0,'rented':0,'family_size':0,'no_of_children':0,'income_bracket':0},inplace=True)\n",
    "train_data_merge['family_size'].astype('int8')\n",
    "train_data_merge['no_of_children'].astype('int8')\n",
    "train_data_merge = pd.get_dummies(train_data_merge, columns=['brand_type','category'], drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data_merge.drop('redemption_status', axis=1)\n",
    "y = train_data_merge['redemption_status']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,train_size=0.7,random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Baseline Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     20278\n",
      "           1       0.67      0.07      0.13      2240\n",
      "\n",
      "    accuracy                           0.90     22518\n",
      "   macro avg       0.79      0.54      0.54     22518\n",
      "weighted avg       0.88      0.90      0.87     22518\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# defining the model\n",
    "classifier = LogisticRegression(solver='lbfgs',max_iter=10000)\n",
    "\n",
    "# fitting the model\n",
    "classifier.fit(X_train,y_train)\n",
    "\n",
    "# predicting test result with model\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Creating Classification report for Logistic Regression Baseline model\n",
    "\n",
    "print (\"Classification Report for Baseline Logistic Regression\")\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "report = pd.DataFrame(classification_report(y_test,y_pred,output_dict=True)).transpose()\n",
    "\n",
    "write_file(file_write_cnt,'No','No','Yes',len(X.columns),list(X.columns),'Logistic Regresssion',report['precision'][1],report['recall'][1],report['support']['accuracy'],'Baseline Model')\n",
    "file_write_cnt = file_write_cnt + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Baseline RandomForest Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     20278\n",
      "           1       0.97      0.82      0.89      2240\n",
      "\n",
      "    accuracy                           0.98     22518\n",
      "   macro avg       0.98      0.91      0.94     22518\n",
      "weighted avg       0.98      0.98      0.98     22518\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# defining the model\n",
    "classifier = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# fitting the model\n",
    "classifier.fit(X_train,y_train)\n",
    "\n",
    "# predicting test result with model\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Creating Classification report for RandomForest Classifier Baseline model\n",
    "\n",
    "print (\"Classification Report for Baseline RandomForest Classifier\")\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "report = pd.DataFrame(classification_report(y_test,y_pred,output_dict=True)).transpose()\n",
    "\n",
    "write_file(file_write_cnt,'No','No','Yes',len(X.columns),X.columns,'Random Forest Classifier',report['precision'][1],report['recall'][1],report['support']['accuracy'],'Baseline Model')\n",
    "file_write_cnt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_data_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_merge = pd.merge(train_data,cust_tran_data_expt,how='inner',on=['customer_id','coupon_id'])\n",
    "train_data_merge = pd.merge(train_data_merge,cust_demo_data,how='left',on='customer_id')\n",
    "train_data_merge = pd.merge(train_data_merge,item_data,how='left',on='item_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_merge['no_of_children'].fillna(0,inplace=True)\n",
    "train_data_merge.fillna({'marital_status':'Unspecified','rented':'Unspecified','family_size':'Unspecified','age_range':'Unspecified'},inplace=True)\n",
    "train_data_merge['income_bracket'].fillna(train_data_merge['income_bracket'].mean(),inplace=True)\n",
    "train_data_merge.drop(['id'],axis=1,inplace=True)\n",
    "train_data_merge['no_of_children'].replace('3+',3,inplace=True)\n",
    "train_data_merge['no_of_children'].astype('int')\n",
    "train_data_merge = pd.get_dummies(train_data_merge, columns=['age_range','marital_status','rented','family_size','brand_type','category'], drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data_merge.drop('redemption_status', axis=1)\n",
    "y = train_data_merge['redemption_status']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,train_size=0.7,random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for RandomForest Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     20278\n",
      "           1       0.96      0.79      0.87      2240\n",
      "\n",
      "    accuracy                           0.98     22518\n",
      "   macro avg       0.97      0.89      0.93     22518\n",
      "weighted avg       0.98      0.98      0.97     22518\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# defining the model\n",
    "classifier = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# fitting the model\n",
    "classifier.fit(X_train,y_train)\n",
    "\n",
    "# predicting test result with model\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Creating Classification report for RandomForest Classifier Baseline model\n",
    "\n",
    "print (\"Classification Report for RandomForest Classifier\")\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "report = pd.DataFrame(classification_report(y_test,y_pred,output_dict=True)).transpose()\n",
    "\n",
    "write_file(file_write_cnt,'No','No','Yes',len(X.columns),X.columns,'Random Forest Classfier',report['precision'][1],report['recall'][1],report['support']['accuracy'],'with OHE')\n",
    "file_write_cnt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_data_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_merge = pd.merge(train_data,cust_tran_data_expt,how='inner',on=['customer_id','coupon_id'])\n",
    "train_data_merge = pd.merge(train_data_merge,cust_demo_data,how='left',on='customer_id')\n",
    "train_data_merge = pd.merge(train_data_merge,item_data,how='left',on='item_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_merge['no_of_children'].fillna(0,inplace=True)\n",
    "train_data_merge.fillna({'marital_status':'Unspecified','rented':'Unspecified','family_size':'Unspecified','age_range':'Unspecified'},inplace=True)\n",
    "train_data_merge['income_bracket'].fillna(train_data_merge['income_bracket'].mean(),inplace=True)\n",
    "train_data_merge['no_of_children'].replace('3+',3,inplace=True)\n",
    "train_data_merge['no_of_children'].astype('int')\n",
    "train_data_merge.drop(['id'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['marital_status','rented','family_size','age_range','brand_type','category']:\n",
    "    label_encode(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data_merge.drop('redemption_status', axis=1)\n",
    "y = train_data_merge['redemption_status']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,train_size=0.7,random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for RandomForest Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     20278\n",
      "           1       0.96      0.82      0.88      2240\n",
      "\n",
      "    accuracy                           0.98     22518\n",
      "   macro avg       0.97      0.91      0.94     22518\n",
      "weighted avg       0.98      0.98      0.98     22518\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# defining the model\n",
    "classifier = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# fitting the model\n",
    "classifier.fit(X_train,y_train)\n",
    "\n",
    "# predicting test result with model\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Creating Classification report for RandomForest Classifier Baseline model\n",
    "\n",
    "print (\"Classification Report for RandomForest Classifier\")\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "report = pd.DataFrame(classification_report(y_test,y_pred,output_dict=True)).transpose()\n",
    "\n",
    "write_file(file_write_cnt,'No','No','Yes',len(X.columns),X.columns,'Random Forest Classifier',report['precision'][1],report['recall'][1],report['support']['accuracy'],'with Label Encoding')\n",
    "file_write_cnt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering with Treatment of Campaign Date, Transaction Date and using Coupon Redemption percentage as a value to convert categorical columns to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_data_merge\n",
    "del cust_tran_data_expt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "campaign_data_expt = campaign_data.copy()\n",
    "campaign_data_expt['start_date_q'] = campaign_data_expt['start_date'].map(lambda x: date_q(x,'/'))\n",
    "campaign_data_expt['end_date_q'] = campaign_data_expt['end_date'].map(lambda x: date_q(x,'/'))\n",
    "campaign_data_expt.drop(['start_date','end_date'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_tran_data_expt = cust_tran_data.copy()\n",
    "cust_tran_data_expt = pd.merge(cust_tran_data_expt,coupon_data,how='inner',on='item_id')\n",
    "cust_tran_data_expt['tran_date_q'] = cust_tran_data_expt['date'].map(lambda x: date_q(x,'-'))\n",
    "cust_tran_data_expt.drop('date',axis=1,inplace=True)\n",
    "\n",
    "for column in ['quantity','coupon_discount','other_discount','selling_price']:\n",
    "    tran_summation_1(column)\n",
    "\n",
    "cust_tran_data_expt.drop_duplicates(subset=['customer_id','item_id','coupon_id','tran_date_q'], keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_merge = pd.merge(train_data,cust_tran_data_expt,how='inner',on=['customer_id','coupon_id'])\n",
    "train_data_merge = pd.merge(train_data_merge,cust_demo_data,how='left',on='customer_id')\n",
    "train_data_merge = pd.merge(train_data_merge,item_data,how='left',on='item_id')\n",
    "train_data_merge = pd.merge(train_data_merge,campaign_data_expt,how='left',on='campaign_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_merge['no_of_children'].fillna(0,inplace=True)\n",
    "train_data_merge.fillna({'marital_status':'Unspecified','rented':'Unspecified','family_size':'Unspecified','age_range':'Unspecified','income_bracket':'Unspecified'},inplace=True)\n",
    "train_data_merge.drop('id',axis=1,inplace=True)\n",
    "train_data_merge['no_of_children'].replace('3+',3,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['customer_id','coupon_id','item_id','campaign_id','no_of_children','marital_status','rented','family_size','age_range','income_bracket','start_date_q','end_date_q','tran_date_q','brand','category']:\n",
    "    cat_percent(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_merge = pd.get_dummies(train_data_merge, columns=['campaign_type','brand_type'], drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data_merge.drop('redemption_status', axis=1)\n",
    "y = train_data_merge['redemption_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features selected are :: 5\n",
      "Columns Selected are :: ['customer_id_redeem_percent', 'coupon_id_redeem_percent', 'item_id_redeem_percent', 'campaign_id_redeem_percent', 'brand_redeem_percent']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     27272\n",
      "           1       0.97      0.97      0.97      3718\n",
      "\n",
      "    accuracy                           0.99     30990\n",
      "   macro avg       0.98      0.98      0.98     30990\n",
      "weighted avg       0.99      0.99      0.99     30990\n",
      "\n",
      "Number of features selected are :: 10\n",
      "Columns Selected are :: ['tot_selling_price', 'customer_id_redeem_percent', 'coupon_id_redeem_percent', 'item_id_redeem_percent', 'campaign_id_redeem_percent', 'family_size_redeem_percent', 'age_range_redeem_percent', 'income_bracket_redeem_percent', 'end_date_q_redeem_percent', 'brand_redeem_percent']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     27272\n",
      "           1       0.98      0.98      0.98      3718\n",
      "\n",
      "    accuracy                           0.99     30990\n",
      "   macro avg       0.99      0.99      0.99     30990\n",
      "weighted avg       0.99      0.99      0.99     30990\n",
      "\n",
      "Number of features selected are :: 15\n",
      "Columns Selected are :: ['tot_coupon_discount', 'tot_other_discount', 'tot_selling_price', 'customer_id_redeem_percent', 'coupon_id_redeem_percent', 'item_id_redeem_percent', 'campaign_id_redeem_percent', 'marital_status_redeem_percent', 'family_size_redeem_percent', 'age_range_redeem_percent', 'income_bracket_redeem_percent', 'end_date_q_redeem_percent', 'brand_redeem_percent', 'category_redeem_percent', 'campaign_type_X']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     27272\n",
      "           1       0.98      0.97      0.97      3718\n",
      "\n",
      "    accuracy                           0.99     30990\n",
      "   macro avg       0.99      0.98      0.98     30990\n",
      "weighted avg       0.99      0.99      0.99     30990\n",
      "\n",
      "Number of features selected are :: 23\n",
      "Columns Selected are :: ['tot_quantity', 'tot_coupon_discount', 'tot_other_discount', 'tot_selling_price', 'customer_id_redeem_percent', 'coupon_id_redeem_percent', 'item_id_redeem_percent', 'campaign_id_redeem_percent', 'no_of_children_redeem_percent', 'marital_status_redeem_percent', 'rented_redeem_percent', 'family_size_redeem_percent', 'age_range_redeem_percent', 'income_bracket_redeem_percent', 'start_date_q_redeem_percent', 'end_date_q_redeem_percent', 'tran_date_q_redeem_percent', 'brand_redeem_percent', 'category_redeem_percent', 'campaign_type_X', 'campaign_type_Y', 'brand_type_Established', 'brand_type_Local']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     27272\n",
      "           1       0.97      0.96      0.97      3718\n",
      "\n",
      "    accuracy                           0.99     30990\n",
      "   macro avg       0.98      0.98      0.98     30990\n",
      "weighted avg       0.99      0.99      0.99     30990\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_sel = [5,10,15,23]\n",
    "\n",
    "rforc = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "for i in feature_sel:\n",
    "    rfe = RFE(rforc, i)\n",
    "    rfe.fit(X, y)\n",
    "\n",
    "# Selecting columns\n",
    "\n",
    "    sel_cols = []\n",
    "    for a, b, c in zip(rfe.support_, rfe.ranking_, X.columns):\n",
    "        if b == 1:\n",
    "            sel_cols.append(c)\n",
    "    print ('Number of features selected are ::',i)\n",
    "    print ('Columns Selected are ::',sel_cols)\n",
    "\n",
    "# Creating new DataFrame with selected columns only as X\n",
    "\n",
    "    X_sel = X[sel_cols]\n",
    "\n",
    "# Split data in to train and test\n",
    "\n",
    "    X_sel_train, X_sel_test, y_sel_train, y_sel_test = train_test_split(X_sel, y, train_size=0.7, random_state=7)\n",
    "    \n",
    "# Fit and Predict the model using selected number of features    \n",
    "    grid={\"n_estimators\":[100]}\n",
    "    rforc_cv = GridSearchCV(rforc,grid,cv=10)\n",
    "    rforc_cv.fit(X_sel_train, y_sel_train)\n",
    "    rforc_pred = rforc_cv.predict(X_sel_test)\n",
    "\n",
    "# Classification Report    \n",
    "    \n",
    "    print(classification_report(y_sel_test,rforc_pred))\n",
    "    \n",
    "    report = pd.DataFrame(classification_report(y_sel_test,rforc_pred,output_dict=True)).transpose()\n",
    "\n",
    "    write_file(file_write_cnt,'No','No','Yes',len(X_sel.columns),X_sel.columns,'Random Forest Classifier',report['precision'][1],report['recall'][1],report['support']['accuracy'],'Treating Date and Label Encoding with RFE')\n",
    "    file_write_cnt += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
